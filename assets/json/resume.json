{
  "basics": {
    "name": "Yuhang Wen",
    "label": "",
    "image": "",
    "email": "wenyh29[at]mail2.sysu.edu.cn",
    "phone": "",
    "url": "https://necolizer.github.io",
    "summary": "",
    "location": {
      "address": "No.66, Gongchang Road",
      "postalCode": "518107",
      "city": "Shenzhen",
      "countryCode": "CN",
      "region": "Guangdong"
    },
    "profiles": [
      {
        "network": "",
        "username": "",
        "url": ""
      }
    ]
  },
  "education": [
    {
      "institution": "Sun Yat-sen University, Guangdong, China",
      "location": "Guangdong, China",
      "url": "",
      "area": "",
      "studyType": "M.Sc.",
      "startDate": "2023-09",
      "endDate": "current",
      "score": "",
      "courses": []
    },
    {
      "institution": "Sun Yat-sen University, Guangdong, China",
      "location": "Guangdong, China",
      "url": "",
      "area": "",
      "studyType": "B.Eng.",
      "startDate": "2019-09",
      "endDate": "2023-08",
      "score": "",
      "courses": []
    }
  ],
  "projects": [
    {
      "name": "Skeleton-based Interaction Recognition",
      "summary": "This project aimed to recognize and understand interactions involving multiple entitiesâ€”such as human bodies, hands, objects, or other elements within a scene. Our goal was to unify the recognition tasks of person-peron, hand-hand, hand-object interactions, and even group activities.",
      "highlights": [
        "Led and played a key role in every aspect of the project, including method design, coding, conducting experiments, result analysis and manuscript writing.",
        "Proposed a model based on entity rearrangement and token attention, achieving SOTA performance across 4 benchmarks.",
        "Enabled the single-entity backbones (e.g., CTR-GCN) to achieve SOTA performance on 6 multi-entity action benchmarks in subsequent research.",
        "Published this work in IROS 2023, with subsequent research published in NeurIPS 2024."
      ],
      "startDate": "2023-01",
      "endDate": "current",
      "url": ""
    },
    {
      "name": "Progressive Reasoning with World Models for Robotic Manipulation",
      "summary": "This project built a robot manipulation simulator based on UE5, which can automatically generate robot manipulation demonstration data containing complex language instructions. With this simulator, we created a robot manipulation benchmark with progressive inference tasks, and proposed a world model-based robot manipulation method.",
      "highlights": [
        "Reviewed recent works related to robotic manipulation and deployed 3+ multimodal models (e.g., BC-Z, RT-1) using PyTorch.",
        "Trained multimodal models using reinforcement learning in the simulation environment to enable accurate comprehension of human language instructions and object grasping."
      ],
      "startDate": "2023-05",
      "endDate": "2023-09",
      "url": ""
    }
  ],
  "publications": [
    {
      "name": "CHASE: Learning Convex Hull Adaptive Shift for Skeleton-based Multi-Entity Action Recognition",
      "publisher": "Thirty-eighth Conference on Neural Information Processing Systems (NeurIPS)",
      "releaseDate": "2024",
      "url": "",
      "summary": ""
    },
    {
      "name": "Facial Prior Guided Micro-Expression Generation",
      "publisher": "IEEE Transactions on Image Processing",
      "releaseDate": "2024",
      "url": "https://ieeexplore.ieee.org/document/10375342",
      "summary": ""
    },
    {
      "name": "Explore Human Parsing Modality for Action Recognition",
      "publisher": "CAAI Transactions on Intelligence Technology",
      "releaseDate": "2024",
      "url": "http://doi.org/10.1049/cit2.12366",
      "summary": ""
    },
    {
      "name": "Interactive Spatiotemporal Token Attention Network for Skeleton-Based General Interactive Action Recognition",
      "publisher": "2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
      "releaseDate": "2023",
      "url": "https://ieeexplore.ieee.org/document/10342472",
      "summary": ""
    },
    {
      "name": "Facial Prior Based First Order Motion Model for Micro-Expression Generation",
      "publisher": "Proceedings of the 29th ACM International Conference on Multimedia",
      "releaseDate": "2021",
      "url": "https://dl.acm.org/doi/10.1145/3474085.3479211",
      "summary": ""
    }
  ],
  "work": [
    {
      "name": "Sony (China) Ltd.",
      "position": "Deep Learning Intern (Sony R&D Center)",
      "url": "https://www.sony.com/en/SonyInfo/research/about/china-laboratory/",
      "startDate": "2024-07",
      "endDate": "2024-09",
      "summary": "",
      "highlights": [
        "Assisted in developing deep learning models on human action analysis, based on skeletal data and RGB-D videos."
      ]
    },
    {
      "name": "Hangzhou Lingxi Robot Intelligent Technology Co., Ltd. (LINX ROBOT)",
      "position": "Algorithm Development Intern (Team Leader)",
      "url": "http://www.linx-robot.com/",
      "startDate": "2022-10",
      "endDate": "2022-12",
      "summary": "",
      "highlights": [
        "Completed a defect detection project utilizing few-shot learning, involving the review of 40+ research papers, archiving 16 open-source datasets, and successfully reproducing 4 key methods.",
        "Completed an image matching and retrieval project, collecting and annotating over 400 images, and fine-tuning DELF and CGD methods, resulting in a 10% increase in top-1 accuracy."
      ]
    }
  ],
  "volunteer": [],
  "awards": [
    {
      "title": "CVPR 2022 5th UG2+ Challenge Second Runner-up",
      "date": "2022-06",
      "awarder": "CVPR 2022 5th UG2+ Workshop Organization Committee",
      "url": "https://cvpr2022.ug2challenge.org/track2.html",
      "summary": "It is awarded to our team (Titan5-HPL) in recognition of our solution submission to Challenge 2: Semi-supervied Action Recognition in the Dark."
    },
    {
      "title": "ACMMM 2021 Facial Micro-Expression (FME) Challenge Winner",
      "date": "2021-10",
      "awarder": "ACMMM 2021 Facial Micro-Expression (FME) Challenge Organization Committee",
      "url": "https://megc2021.github.io/index.html",
      "summary": "It is awarded to our team (Titan5-HPL) for ranking 1st in Facial Micro-Expression Generation Task."
    }
  ],
  "certificates": [],
  "skills": [
    {
      "name": "Programming",
      "level": "",
      "icon": "fa-solid fa-hashtag",
      "keywords": ["Python", "C/C++", "C#"]
    },
    {
      "name": "Deep Learning",
      "level": "",
      "icon": "fa-solid fa-hashtag",
      "keywords": ["PyTorch", "Tensorflow", "Work with Multi-GPU Server & GPU Cluster"]
    }
  ],
  "languages": [
    {
      "language": "Mandarin",
      "fluency": "Native",
      "icon": ""
    },
    {
      "language": "English",
      "fluency": "Fluent",
      "icon": ""
    },
    {
      "language": "Japanese",
      "fluency": "Basic",
      "icon": ""
    }
  ],
  "interests": [],
  "references": [
    {
      "name": "Prof. Mengyuan Liu",
      "icon": "fa-solid fa-thumbtack",
      "reference": "Peking University"
    },
    {
      "name": "Prof. Beichen Ding",
      "icon": "fa-solid fa-thumbtack",
      "reference": "Sun Yat-sen University"
    }
  ]
}
